{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd, numpy as np\n",
    "from scipy import stats\n",
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Objective\n",
    "We have an A/B test data from a mobile game <a href=\"https://www.facebook.com/cookiecatsgame\">Cookie Cats</a>, where we are going to analyse players' retention with different treatment of prompt in-app purchases __gates__. As shown below, the __gate__ will show up as players progresses through the levels of the game.\n",
    "<p><img src=\"https://s3.amazonaws.com/assets.datacamp.com/production/project_184/img/cc_gates.png\" alt=\"\"></p>\n",
    "In this experiment, the developer wants to know whether placing the gate at level 40 will boost more players' retention compared to the gate at level 30. Full description and preliminary A/B test analysis can be found on <a href=\"https://www.datacamp.com/projects/184\">Datacamp project page</a>.\n",
    "\n",
    "However, I am going to explore several other options of assessing A/B test results besides the method of bootstrap sampling that is explained on the Datacamp page.\n",
    "\n",
    "The result, however, shows that putting the gate at level 40 is ineffective and the retention is lower than the group where the gate shows up at level 30. We will confirm this through other ways that we are going to perform."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. The data\n",
    "The players are randomly assigned into two groups: `gate_30` and `gate_40` under the column `version` on the dataset. The total players in this dataset is 90,189 with no duplicate `userid`. Also, we have other fields such as:\n",
    "<ul>\n",
    "<li><code>sum_gamerounds</code> (the number of game rounds played by the player during the first 14 days after install),\n",
    "<li><code>retention_1</code> - did the player come back and play <strong>1 day</strong> after installing?</li>\n",
    "<li><code>retention_7</code> - did the player come back and play <strong>7 days</strong> after installing?</li>\n",
    "</ul>\n",
    "\n",
    "A sneak peek of the data gives us below depiction,"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>userid</th>\n",
       "      <th>version</th>\n",
       "      <th>sum_gamerounds</th>\n",
       "      <th>retention_1</th>\n",
       "      <th>retention_7</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>38670</th>\n",
       "      <td>4283520</td>\n",
       "      <td>gate_40</td>\n",
       "      <td>112</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2502</th>\n",
       "      <td>275887</td>\n",
       "      <td>gate_30</td>\n",
       "      <td>2</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>72539</th>\n",
       "      <td>8037409</td>\n",
       "      <td>gate_40</td>\n",
       "      <td>3</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7912</th>\n",
       "      <td>871500</td>\n",
       "      <td>gate_30</td>\n",
       "      <td>2961</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>87165</th>\n",
       "      <td>9656426</td>\n",
       "      <td>gate_40</td>\n",
       "      <td>0</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        userid  version  sum_gamerounds  retention_1  retention_7\n",
       "38670  4283520  gate_40             112         True         True\n",
       "2502    275887  gate_30               2        False        False\n",
       "72539  8037409  gate_40               3        False        False\n",
       "7912    871500  gate_30            2961         True         True\n",
       "87165  9656426  gate_40               0        False        False"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv(\"datasets/cookie_cats.csv\")\n",
    "df.sample(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We are more interested in using `retention_7` than `retention_1` column since it is very unlikely to have player hits either level 30 or level 40 after only 1 day installing the game.\n",
    "\n",
    "However, one important thing to ensure first whether the size of the A/B groups is roughly proportional."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "version\n",
       "gate_30    44700\n",
       "gate_40    45489\n",
       "dtype: int64"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.groupby(['version']).size()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "And to see whether the difference below is significant?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>version</th>\n",
       "      <th>retention_7</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>gate_30</td>\n",
       "      <td>0.190201</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>gate_40</td>\n",
       "      <td>0.182000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   version  retention_7\n",
       "0  gate_30     0.190201\n",
       "1  gate_40     0.182000"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.groupby(['version'], as_index=False)['retention_7'].mean()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### a. Is the data already sufficient enough?\n",
    "Before conducting an A/B test it is imperative to determine the minimum sample size in order to ensure minimum detectable effect. Having inadequate samples will likely give uncertain results and we might not be able to detect changes where it is actually there. \n",
    "\n",
    "We want to minimize this probability of not admitting a change while there is actually a change, or in other words also called as __false negative__ or __Type-II error__.\n",
    "\n",
    "However, it is more common to define the converse of it, i.e. __true positive__ or __power__ of the statistical test. We want the probability of accepting the positive change while actually there is indeed a positive change is as high as possible. As we will see, higher sample size will lead to an increase in power.\n",
    "\n",
    "Referring to <a href=\"https://books.google.co.id/books/about/Sample_Size_Calculations_in_Clinical_Res.html?id=7_0wDwAAQBAJ&printsec=frontcover&source=kp_read_button&redir_esc=y#v=onepage&q&f=false\">this book</a> which dedicated wholly to discuss sample size, the formula to determining the sample size for measuring proportion difference between two groups is"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$$n_1=n_2=\\frac{(z_{\\alpha/2}+z_\\beta)^2 (p_1(1-p_1)+p_2(1-p_2))}{\\epsilon^2}$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "where \n",
    "<li>$z_{\\alpha/2}$ is normal quantile value at $\\alpha/2$ significance level (usually $\\alpha=5\\%$),\n",
    "<li>$z_{\\beta}$ is normal quantile value at $\\beta$ (usually $\\beta=20\\%)$ that gives 80% power,\n",
    "<li>$p_1$ is baseline conversion rate (i.e. 0.190201 in this data),\n",
    "<li>$\\epsilon$ is the minimum detectable effect or effect size which predetermined based on business needs,\n",
    "<li>$p_2 = p_1 + \\epsilon$ is the aimed uplift on the treatment group,</li>\n",
    "\n",
    "Note that we already have $p_2$ in our data, i.e. 0.182. Before conducting an A/B test, we definitely have no idea what the quantity of $p_2$ is and of course we are not aiming for decrease in retention rate.\n",
    "\n",
    "Let's try to make a simulation with varying minimum detectable effect; 0.01, 0.02, 0.04, 0.08, 0.16 respectively."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[24656.90692, 6279.91869, 1624.88232, 430.72858, 116.99281]\n"
     ]
    }
   ],
   "source": [
    "mdes = [.01, .02, .04, .08, .16]\n",
    "ssize = []\n",
    "power = 0.8\n",
    "alpha = 0.05\n",
    "p1 = df.groupby(['version']).retention_7.mean()[0]\n",
    "\n",
    "for mde in mdes:\n",
    "    p2 = p1 + mde\n",
    "    n = (stats.norm.ppf(1-alpha/2) + stats.norm.ppf(power))**2 * (p1 * (1-p1) + p2 * (1-p2)) / mde**2\n",
    "    ssize.append(round(n, 5))\n",
    "\n",
    "print(ssize)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As you may notice as the minimum detectable effect getting smaller, more sample size is needed in order the test to be able to detect the possible effects. Since the sample in our data is around 40 thousand for each group, it seems the statistical power is already high enough to avoid Type-II error given the simulation above."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Comparing Two Proportions (Hypothesis test, p-value, and confidence interval)\n",
    "### a. Hypothesis test\n",
    "This is a classical-way (frequentist) of comparing proportions between two groups. Firstly, we test the null hypothesis where\n",
    "\n",
    "$$H_0: p_1 - p_2 = 0$$\n",
    "\n",
    "with test statistic that asymptotically follows standard normal distribution as\n",
    "\n",
    "$$\\begin{aligned}\n",
    "Z &= \\frac{(\\hat{p}_1-\\hat{p}_2) - (p_1-p_2)}{\\sqrt{\\hat{p}(1-\\hat{p})\\left(\\frac{1}{n_1}+\\frac{1}{n_2}\\right)}} \\\\\n",
    "\\end{aligned}$$\n",
    "\n",
    "where the pooled proportion is\n",
    "\n",
    "$$\\hat{p} = \\frac{Y_1+Y_2}{n_1+n_2}$$\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The test statistic $Z$ consists of numerator $\\hat{p}_1-\\hat{p}_2$ (`gate_30` group $-$ `gate_40` group) which is our point estimate and $p_1-p_2$ as the value we want to compare with (i.e. zero). The denominator is basically the estimated standard deviation of retention difference, namely $\\text{SD}(p_1-p_2)$ or $\\sqrt{\\text{Var}(p_1-p_2)}$. I would recommend to look onto <a href=\"https://newonlinecourses.science.psu.edu/stat414/node/268/\">this explanation</a> for a brief derivation of the formula. Computing the values, "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3.164\n"
     ]
    }
   ],
   "source": [
    "df_grp = df.groupby(['version'])\n",
    "p1_hat = df_grp.retention_7.mean()[0]\n",
    "p2_hat = df_grp.retention_7.mean()[1]\n",
    "n1 = df_grp.retention_7.size()[0]\n",
    "n2 = df_grp.retention_7.size()[1]\n",
    "Y1 = df_grp.retention_7.sum()[0]\n",
    "Y2 = df_grp.retention_7.sum()[1]\n",
    "\n",
    "phat = (Y1+Y2)/(n1+n2)\n",
    "Z = (p1_hat - p2_hat) / np.sqrt(phat * (1-phat) * (1/n1 + 1/n2))\n",
    "print(round(Z, 3))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "we obtain $Z=3.164$ and as you may remember this value is within the rejection region at 5% significance level (where the threshold is $\\pm{1.96}$). Therefore __we reject the null and conclude that players on group `gate_30` has significantly different (i.e. higher) retention rate than players on group `gate_40`__. Sadly, moving the gate to level 40 turns out to lower the retention rate of the players."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### b. P-value approach\n",
    "Either way, we could find the p-value of this result. Finding the probability of the tails on both side with $Z=\\pm{3.164}$, we obtain"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.0015542499756142636"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "2 * (1 - stats.norm.cdf(Z))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "which is reasonably small (p-value $< 0.05$) and the conclusion still holds the same. \n",
    "\n",
    "If you are lazy enough and not knowing the formula, we can however utilize one of the scipy stats methods which returns the exact same quantile and p-value. But first we need to input the values in either 0/1 form."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Ttest_indResult(statistic=3.1644994996802778, pvalue=0.0015540151201088365)"
      ]
     },
     "execution_count": 101,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "grp_A = df[df.version=='gate_30'].retention_7.replace({True: 1, False: 0})\n",
    "grp_B = df[df.version=='gate_40'].retention_7.replace({True: 1, False: 0})\n",
    "stats.ttest_ind(grp_A, grp_B)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### c. Confidence interval\n",
    "Lastly, we could alternatively find the confidence interval of the retention difference. If the confidence interval happens to contain zero, then it is likely that the difference is not statistically significant and we cannot safely conclude the retention is different between the groups. Remember that the confidence interval formula goes like this"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$$\\text{point estimate} \\ \\pm \\ \\text{critical value} \\ \\times \\sqrt{\\text{Var(point estimate)}}$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "and for our case it is"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$$(\\hat{p}_1-\\hat{p}_2) \\ \\pm z_{\\alpha/2} \\ \\times \\sqrt{\\frac{\\hat{p}_1(1-\\hat{p}_1)}{n_1} + \\frac{\\hat{p}_2(1-\\hat{p}_2)}{n_2}}$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For this case, we have a slightly difference variance of the point estimate than we had earlier. For the reason why, refer to <a href=\"https://newonlinecourses.science.psu.edu/stat414/node/209/\"> this link</a> for the explanation. Then we obtain the confidence interval within"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(0.00312, 0.01328)\n"
     ]
    }
   ],
   "source": [
    "marg_err = stats.norm.ppf(0.975) * np.sqrt((p1_hat * (1-p1_hat) / n1) + (p2_hat * (1- p2_hat) / n2))\n",
    "low_bnd = (p1_hat - p2_hat) - marg_err\n",
    "upp_bnd = (p1_hat - p2_hat) + marg_err\n",
    "conf_int = (round(low_bnd, 5), round(upp_bnd, 5))\n",
    "print(conf_int)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The confidence interval suggests the retention difference is indeed statistically significant."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Bayesian analysis\n",
    "Another useful method to analyse the A/B test result is using Bayesian framework. It offers a more interpretable question to business stakeholders such as __\"what is the probability putting the gate at level 40 gives more retention than putting the gates at level 30?\"__ instead of frequentist approach that states mere statistical significance (also there has been a long-standing debate surrounding the use of p-value).\n",
    "\n",
    "In Bayesian inference, typically we have the following formula:\n",
    "\n",
    "$$p(\\theta | y) \\propto p(\\theta) \\ \\times \\ p(y | \\theta)$$\n",
    "\n",
    "where it means our belief regarding a parameter (i.e. $\\theta$ is retention rate in this case) given the observed data is proportional with our __prior__ belief about the parameter multiplied by the __likelihood__ of the observation that we believe stems from the given parameter. The LHS part of the equation often called as __posterior__. We need to determine the statistical distribution of these three components.\n",
    "\n",
    "In the end, we then sample the posterior distribution by doing Monte Carlo simulation and analyse the results from the generated samples.\n",
    "\n",
    "### a. Likelihood function\n",
    "Now, you might notice that the retention rate on each group is a series of Bernoulli trials (come back 7 days after installation or not) i.e. __distributed binomially__ (actually this plays part as well in the derivation on the frequentist part earlier). These series of Bernoulli trials is our __likelihood distributions__ or we denote that as \n",
    "\n",
    "$$y|\\theta \\sim \\text{Binomial}(n, \\theta)$$ \n",
    "\n",
    "with $n$ trials and $y$ successes (showing up) with probability $\\theta$.\n",
    "\n",
    "### b. Prior distribution\n",
    "What about the __prior distribution__, the prior belief about the retention rate? One thing for sure is that the retention rate is a value within [0, 1] and a __beta distribution__ seems to have this range of value so we decide to choose this distribution as our prior. \n",
    "\n",
    "However, we can actually use any kind of prior besides beta distribution that has support between 0 and 1 (such as gamma distribution), but there is a nice thing about beta distribution with binomial distribution. They have a __conjugacy__ property that allows for mathematical convenience; i.e. the posterior distribution will be also of the form of prior distribution but with updated parameters. \n",
    "\n",
    "### c. Posterior distribution\n",
    "Now, consider $\\theta \\sim \\text{Beta}(a, b)$, then the preceding formula becomes\n",
    "\n",
    "$$\\begin{aligned}\n",
    "p(\\theta | y) &\\propto \\theta^{a-1}(1-\\theta)^{b-1} \\ \\times \\theta^{y}(1-\\theta)^{n-y} \\\\\n",
    "&\\propto \\theta^{a+y-1}(1-\\theta)^{b+n-y-1} \\\\\n",
    "\\end{aligned}$$\n",
    "\n",
    "Then our posterior distribution is also a beta distribution with the following parameter\n",
    "\n",
    "$$\\theta | y \\sim \\text{Beta}(a+y, b+n-y)$$\n",
    "\n",
    "here I omitted $\\frac{\\Gamma(a+b)}{\\Gamma(a)\\Gamma(b)}$ and ${n \\choose y}$ term on both the beta and binomial density above since they give no contribution to the parameter $\\theta$. The posterior distribution above can also be rephrased as\n",
    "\n",
    "$$\\theta | y \\sim \\text{Beta}(a+\\text{successes}, b+\\text{failures})$$\n",
    "\n",
    "The next __important__ step is we compute the posterior distribution of each control and treatment group and simulate the samples out of it using Monte Carlo procedures as many as possible. We then compare the Monte Carlo samples between the two groups.\n",
    "\n",
    "For now, we set the prior as $\\theta \\sim \\text{Beta}(1, 1)$ which is also called __non-informative prior__, since it gives basically no information/emphasize towards particular value of the parameter that we want to measure. We will discuss how to choose prior on next post.\n",
    "\n",
    "The probability having more retention by moving the gate to level 40 is then"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.083%\n"
     ]
    }
   ],
   "source": [
    "a, b = 1, 1\n",
    "nsize = 10**6\n",
    "posterior_gate_30 = np.random.beta(a + Y1, b + n1 - Y1, size=nsize)\n",
    "posterior_gate_40 = np.random.beta(a + Y2, b + n2 - Y2, size=nsize)\n",
    "\n",
    "prob = np.mean(posterior_gate_40 > posterior_gate_30)\n",
    "print(\"{:.3f}%\".format(prob*100))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "so it is unwise to move the gate to level 40 as the probability is very small."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### d. Intro to PyMC3: probabilistic programming library\n",
    "PyMC3 is a versatile library to perform Bayesian inference. It has many advanced sampling methods, even the default sampler is the <a href=\"http://elevanth.org/blog/2017/11/28/build-a-better-markov-chain/\">No U-Turn Sampling (NUTS)</a> algorithm, one of the recent variant of Monte Carlo method that handles intractable posterior distribution; posterior that cannot be solved analytically because of not using conjugate prior in the model specification.\n",
    "\n",
    "It might be an overkill to use PyMC3 in this problem since the posterior already has a nice beta distribution form, but this part serves as a useful warm-up before we further discuss Bayesian inference in the next blog post."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/dims/anaconda3/lib/python3.6/site-packages/h5py/__init__.py:34: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  from ._conv import register_converters as _register_converters\n",
      "Auto-assigning NUTS sampler...\n",
      "Initializing NUTS using jitter+adapt_diag...\n",
      "Multiprocess sampling (2 chains in 2 jobs)\n",
      "NUTS: [theta40, theta30]\n",
      "Sampling 2 chains: 100%|██████████| 11000/11000 [00:55<00:00, 198.22draws/s]\n"
     ]
    }
   ],
   "source": [
    "import pymc3 as pm\n",
    "\n",
    "gate30 = np.array(df[df.version=='gate_30']['retention_7'].replace({False: 0, True: 1}))\n",
    "gate40 = np.array(df[df.version=='gate_40']['retention_7'].replace({False: 0, True: 1}))\n",
    "\n",
    "with pm.Model() as model:\n",
    "    # Priors\n",
    "    gate30_prior = pm.Beta('theta30', alpha=a, beta=b)\n",
    "    gate40_prior = pm.Beta('theta40', alpha=a, beta=b)\n",
    "    \n",
    "    # Likelihood\n",
    "    gate30_ylike = pm.Bernoulli('y30', p=gate30_prior, observed=gate30)\n",
    "    gate40_ylike = pm.Bernoulli('y40', p=gate40_prior, observed=gate40)\n",
    "    \n",
    "    # Difference\n",
    "    retention_diff = pm.Deterministic('diff', gate40_prior-gate30_prior)\n",
    "    \n",
    "    # The inference button\n",
    "    trace = pm.sample(5000)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The probability of getting higher retention rate by putting the gate at level 40 is"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.001"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.mean(trace['theta40'] > trace['theta30'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "One nice thing with PyMC3 it can give us the following sample distribution."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([<matplotlib.axes._subplots.AxesSubplot object at 0x123b0ddd8>],\n",
       "      dtype=object)"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "pm.plot_posterior(trace, var_names=['diff'], ref_val=0, textsize=12, figsize=(6,4))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The figure tells us that the probability of moving the gate to level 40 gives more retention is 0%, which also means 100% of the time putting the gate as it was is more effective than at the gate level 40. \n",
    "\n",
    "The HPD stands for __highest posterior density__ that in this case shows us by moving the gate at level 40, 94% of the time the retention rate difference will be between -1.3% and -0.34%, which also actually worse no matter we repeat the experiment!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Generalized Linear Model\n",
    "I was thinking that given the data we have below"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>userid</th>\n",
       "      <th>version</th>\n",
       "      <th>sum_gamerounds</th>\n",
       "      <th>retention_1</th>\n",
       "      <th>retention_7</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>26716</th>\n",
       "      <td>2976967</td>\n",
       "      <td>gate_40</td>\n",
       "      <td>21</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17502</th>\n",
       "      <td>1949342</td>\n",
       "      <td>gate_30</td>\n",
       "      <td>5</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8023</th>\n",
       "      <td>885695</td>\n",
       "      <td>gate_40</td>\n",
       "      <td>16</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>54036</th>\n",
       "      <td>5998556</td>\n",
       "      <td>gate_40</td>\n",
       "      <td>73</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>56832</th>\n",
       "      <td>6298836</td>\n",
       "      <td>gate_30</td>\n",
       "      <td>3</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        userid  version  sum_gamerounds  retention_1  retention_7\n",
       "26716  2976967  gate_40              21         True        False\n",
       "17502  1949342  gate_30               5        False        False\n",
       "8023    885695  gate_40              16        False        False\n",
       "54036  5998556  gate_40              73         True         True\n",
       "56832  6298836  gate_30               3        False        False"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.sample(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "we can actually fit a linear model by treating `retention_7` as independent variable and the rest as dependent variables (except `userid`). Given this situation, we can fit a probit or logit model. It is actually quite common, especially in econometrics, to employ this method to compare changes between groups. Later, we will see whether the fitted coefficient of `version` is statistically significant and has positive value.\n",
    "\n",
    "Firstly, we one-hot encode these categorical covariates."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import LabelEncoder\n",
    "import statsmodels.api as sm\n",
    "\n",
    "le = LabelEncoder()\n",
    "categorical = ['version', 'retention_1', 'retention_7']\n",
    "df_prepro = df.copy()\n",
    "\n",
    "for col in categorical:\n",
    "    df_prepro[col] = le.fit_transform(df_prepro[col])\n",
    "df_prepro.sample(5)\n",
    "\n",
    "y = df_prepro['retention_7']\n",
    "X = df_prepro.drop(['retention_7','userid'], axis=1)\n",
    "X = sm.add_constant(X)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### a. Probit model\n",
    "Probit model is one of the generalised linear model where the response variable is binary and the estimated coefficient is found through maximum-likelihood estimation procedure. It has __probit link function__ that \"connects\" the linear combination of dependent variables which expressed as\n",
    "\n",
    "$$p(y=1|X) = \\Phi\\left(\\beta^T X\\right)$$\n",
    "\n",
    "where notation $\\Phi$ denotes the standard normal distribution. Following we utilize the statsmodels library to fit the model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Optimization terminated successfully.\n",
      "         Current function value: 0.329974\n",
      "         Iterations 10\n",
      "                          Probit Regression Results                           \n",
      "==============================================================================\n",
      "Dep. Variable:            retention_7   No. Observations:                90189\n",
      "Model:                         Probit   Df Residuals:                    90185\n",
      "Method:                           MLE   Df Model:                            3\n",
      "Date:                Mon, 30 Dec 2019   Pseudo R-squ.:                  0.3132\n",
      "Time:                        17:22:35   Log-Likelihood:                -29760.\n",
      "converged:                       True   LL-Null:                       -43333.\n",
      "                                        LLR p-value:                     0.000\n",
      "==================================================================================\n",
      "                     coef    std err          z      P>|z|      [0.025      0.975]\n",
      "----------------------------------------------------------------------------------\n",
      "const             -1.6915      0.011   -155.157      0.000      -1.713      -1.670\n",
      "version           -0.0376      0.011     -3.280      0.001      -0.060      -0.015\n",
      "sum_gamerounds     0.0096   8.58e-05    111.432      0.000       0.009       0.010\n",
      "retention_1        0.4040      0.013     32.029      0.000       0.379       0.429\n",
      "==================================================================================\n"
     ]
    }
   ],
   "source": [
    "probit_mod = sm.Probit(y, X)\n",
    "probit_res = probit_mod.fit()\n",
    "\n",
    "print(probit_res.summary())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The fitted coefficient value for `version` is $\\beta_1=-0.0376$. This negative sign indicates that a change of gate placement to level 40, will decrease the probability a player to show up after 7 days installing the game (since we have mapped 0 as `gate_30` and 1 as `gate_40`).\n",
    "\n",
    "Also, Wald's hypothesis test can be performed to test whether the fitted coefficient on `version` is significantly different from zero. Wald's principle states that the following statistic asymptotically goes to standard normal distribution\n",
    "\n",
    "$$\\frac{\\hat{\\beta}-\\beta_0}{\\hat{\\text{SE}}(\\hat{\\beta})} \\sim \\text{N}(0,1)$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "we test the coefficient and the p-value it has is"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.0010383866526273908"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "2 * stats.norm.cdf(probit_res.params[1], loc=0, scale=probit_res.bse[1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Altogether, we can safely assume the effect of moving the gate to level 40 will decrease the retention rate and it is statistically significant since the Wald's statistic is considerably small (less than 5% significant level)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### b. Logit model\n",
    "Similar to probit model, logit model or logistic regression model gives output that only takes two values. The linear combination of covariates is \"connected\" through a __logit link function__ as follows\n",
    "\n",
    "$$\\text{log}\\frac{p(y=1|X)}{1-p(y=1|X)} = \\beta^TX$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Optimization terminated successfully.\n",
      "         Current function value: 0.327800\n",
      "         Iterations 8\n",
      "                           Logit Regression Results                           \n",
      "==============================================================================\n",
      "Dep. Variable:            retention_7   No. Observations:                90189\n",
      "Model:                          Logit   Df Residuals:                    90185\n",
      "Method:                           MLE   Df Model:                            3\n",
      "Date:                Mon, 30 Dec 2019   Pseudo R-squ.:                  0.3177\n",
      "Time:                        17:23:50   Log-Likelihood:                -29564.\n",
      "converged:                       True   LL-Null:                       -43333.\n",
      "                                        LLR p-value:                     0.000\n",
      "==================================================================================\n",
      "                     coef    std err          z      P>|z|      [0.025      0.975]\n",
      "----------------------------------------------------------------------------------\n",
      "const             -2.9677      0.022   -136.456      0.000      -3.010      -2.925\n",
      "version           -0.0792      0.021     -3.693      0.000      -0.121      -0.037\n",
      "sum_gamerounds     0.0184      0.000     95.529      0.000       0.018       0.019\n",
      "retention_1        0.6839      0.025     27.868      0.000       0.636       0.732\n",
      "==================================================================================\n"
     ]
    }
   ],
   "source": [
    "logit_mod = sm.Logit(y, X)\n",
    "logit_res = logit_mod.fit()\n",
    "print(logit_res.summary())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The fitted coefficient of `version` is again has negative sign and significant. The conclusion holds the same, although this model estimates more decrease in retention rate $(\\beta_1 = -0.0792)$ compared to the probit model earlier."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### c. Additional analysis\n",
    "Interestingly, both `sum_gamerounds` and `retention_1` are also significant and has positive sign. This can be thought as \n",
    "<ul>\n",
    "<li> The more people spend their time playing the game the more likely they are going to login the game again after 7 days (although this variable measures the playing time for the first 14-day),</li>\n",
    "<li> Having a player comes back the day after installing the game also increases the probability to show up a week later.\n",
    "</ul>"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
